{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import edward as ed\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy.random as npr\n",
    "\n",
    "from tensorflow.contrib import slim\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from edward.models import Uniform\n",
    "from edward.models import Categorical, InverseGamma, Mixture, MultivariateNormalDiag, Normal\n",
    "from scipy.stats import multivariate_normal as mnormal\n",
    "import tensorflow.contrib.distributions as tfd\n",
    "\n",
    "ed.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "M = 64 # batch size during training\n",
    "leak = 0.2 # leak parameter for leakyrelu\n",
    "num_iter = 40000\n",
    "DIR = \"../../../data/bags2shoes\"\n",
    "\n",
    "IMG_DIR = \"../plots/bags2shoes_shared_rev_4\"\n",
    "\n",
    "if os.path.exists(IMG_DIR):\n",
    "    shutil.rmtree(IMG_DIR)\n",
    "\n",
    "os.makedirs(IMG_DIR)\n",
    "os.makedirs(IMG_DIR+'/trainA/')\n",
    "os.makedirs(IMG_DIR+'/trainB/')\n",
    "os.makedirs(IMG_DIR+'/trainBA/')\n",
    "os.makedirs(IMG_DIR+'/trainAB/')\n",
    "os.makedirs(IMG_DIR+'/trainABA/')\n",
    "os.makedirs(IMG_DIR+'/trainBAB/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "if len(glob.glob(DIR + '/*.npy')) == 0:\n",
    "    filelist_1 = glob.glob(DIR + '/bags/*.jpg')\n",
    "    filelist_2 = glob.glob(DIR + '/shoes/*.jpg')\n",
    "    xs = np.array([np.array(Image.open(fname)) for fname in filelist_1])\n",
    "    ys = np.array([np.array(Image.open(fname)) for fname in filelist_2])\n",
    "    np.save(DIR + '/xs.npy', xs)\n",
    "    np.save(DIR + '/ys.npy', ys)\n",
    "else:\n",
    "    xs = np.load(DIR + '/xs.npy')\n",
    "    ys = np.load(DIR + '/ys.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_ph = tf.placeholder(tf.float32, [M, 64, 64, 3])\n",
    "x_ph = tf.placeholder(tf.float32, [M, 64, 64, 3])\n",
    "phase = tf.placeholder(tf.bool)\n",
    "drop = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(samples):\n",
    "  fig = plt.figure(figsize=(4, 4))\n",
    "  plt.title(str(samples))\n",
    "  gs = gridspec.GridSpec(4, 4)\n",
    "  gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "  for i, sample in enumerate(samples):\n",
    "    ax = plt.subplot(gs[i])\n",
    "    plt.axis('off')\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_aspect('equal')\n",
    "    plt.imshow(sample)\n",
    "  return fig\n",
    "\n",
    "\n",
    "def leakyrelu(x, alpha=leak):\n",
    "    return tf.maximum(x, alpha * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encoder(y, phase, drop):\n",
    "    h = tf.layers.conv2d(y, 32, 5, padding='same')\n",
    "    h = slim.batch_norm(h, center=True, scale=True, is_training=phase)\n",
    "    h = tf.nn.relu(h)\n",
    "    h = tf.layers.conv2d(h, 64, 5, padding='same')\n",
    "    h = slim.batch_norm(h, center=True, scale=True, is_training=phase)\n",
    "    h = tf.nn.relu(h)\n",
    "    h = tf.layers.conv2d(h, 128, 5, padding='same')\n",
    "    h = slim.batch_norm(h, center=True, scale=True, is_training=phase)\n",
    "    h = tf.nn.relu(h)\n",
    "    h = tf.layers.conv2d_transpose(h, 128, 5, padding='same')\n",
    "    h = slim.batch_norm(h, center=True, scale=True, is_training=phase)\n",
    "    h = tf.nn.relu(h)\n",
    "    h = tf.layers.conv2d_transpose(h, 64, 5, padding='same')\n",
    "    h = slim.batch_norm(h, center=True, scale=True, is_training=phase)\n",
    "    h = tf.nn.relu(h)\n",
    "    h = tf.layers.conv2d_transpose(h, 32, 5, padding='same')\n",
    "    h = slim.batch_norm(h, center=True, scale=True, is_training=phase)\n",
    "    h = tf.nn.relu(h)\n",
    "    h = tf.layers.conv2d_transpose(h, 3, 5, padding='same')\n",
    "    return tf.nn.tanh(h)\n",
    "\n",
    "def decoder(x, phase, drop):\n",
    "    h = tf.layers.conv2d(x, 32, 5, padding='same')\n",
    "    h = slim.batch_norm(h, center=True, scale=True, is_training=phase)\n",
    "    h = tf.nn.relu(h)\n",
    "    h = tf.layers.conv2d(h, 64, 5, padding='same')\n",
    "    h = slim.batch_norm(h, center=True, scale=True, is_training=phase)\n",
    "    h = tf.nn.relu(h)\n",
    "    h = tf.layers.conv2d(h, 128, 5, padding='same')\n",
    "    h = slim.batch_norm(h, center=True, scale=True, is_training=phase)\n",
    "    h = tf.nn.relu(h)\n",
    "    h = tf.layers.conv2d_transpose(h, 128, 5, padding='same')\n",
    "    h = slim.batch_norm(h, center=True, scale=True, is_training=phase)\n",
    "    h = tf.nn.relu(h)\n",
    "    h = tf.layers.conv2d_transpose(h, 64, 5, padding='same')\n",
    "    h = slim.batch_norm(h, center=True, scale=True, is_training=phase)\n",
    "    h = tf.nn.relu(h)\n",
    "    h = tf.layers.conv2d_transpose(h, 32, 5, padding='same')\n",
    "    h = slim.batch_norm(h, center=True, scale=True, is_training=phase)\n",
    "    h = tf.nn.relu(h)\n",
    "    h = tf.layers.conv2d_transpose(h, 3, 5, padding='same')\n",
    "    return tf.nn.tanh(h)\n",
    "\n",
    "\n",
    "def discriminative_network(y):\n",
    "    h = tf.layers.conv2d(y, 32, 5, activation=leakyrelu, padding='same')\n",
    "#    h = tf.layers.dropout(h,drop)\n",
    "    h = tf.layers.conv2d(h, 64, 5, activation=leakyrelu, padding='same')\n",
    "#    h = tf.layers.dropout(h,drop)\n",
    "    h = tf.layers.conv2d(h, 64, 5, activation=leakyrelu, padding='same')\n",
    "#    h = tf.layers.dropout(h,drop)\n",
    "    h = tf.layers.conv2d(h, 64, 5, activation=leakyrelu, padding='same')\n",
    "#    h = tf.layers.dropout(h,drop)\n",
    "    h = tf.layers.conv2d(h, 128, 5, activation=leakyrelu, padding='same')\n",
    "#    h = tf.layers.dropout(h,drop)\n",
    "    h = tf.layers.conv2d(h, 128, 5, activation=leakyrelu, padding='same')\n",
    "#    h = tf.layers.dropout(h,drop)\n",
    "    h = tf.layers.conv2d(h, 128, 5, activation=leakyrelu, padding='same')\n",
    "#    h = tf.layers.dropout(h,drop)\n",
    "    h = tf.reshape(h,[M,-1])\n",
    "    logit = slim.fully_connected(h, 1,activation_fn=None)\n",
    "    return logit\n",
    "\n",
    "with tf.variable_scope(\"Gen\"):\n",
    "  yf = decoder(x_ph, phase, drop)\n",
    "  xf = encoder(y_ph, phase, drop)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(0.00001, 0.5, 0.9)\n",
    "optimizer_d = tf.train.AdamOptimizer(0.00001, 0.5, 0.9)\n",
    "#optimizer = tf.train.RMSPropOptimizer(0.00005)\n",
    "#optimizer_d = tf.train.RMSPropOptimizer(0.00005)\n",
    "\n",
    "\n",
    "inference = ed.sharedWGANInference(\n",
    "    data={yf: y_ph, xf: x_ph}, discriminator=discriminative_network)\n",
    "\n",
    "inference.initialize(\n",
    "    optimizer = optimizer, optimizer_d=optimizer_d, n_iter=50000, n_print=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize The Session\n",
    "sess = ed.get_session()\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "i = 0\n",
    "j = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Printing images for iteration: 0\n",
      "  600/50000 [  1%]                                ETA: 66362s | Gen Loss: 108.527 | Disc Loss: 0.000\n",
      " Printing images for iteration: 1\n",
      "  900/50000 [  1%]                                ETA: 65560s | Gen Loss: 107.876 | Disc Loss: 0.000"
     ]
    }
   ],
   "source": [
    "for t in range(inference.n_iter):\n",
    "  rndint_y = np.random.choice(len(ys),M,replace=False)\n",
    "  rndint_x = np.random.choice(len(xs),M,replace=False)\n",
    "  y_batch = ys[rndint_y,:,:,:]/127.5 - 1.\n",
    "  x_batch = xs[rndint_x,:,:,:]/127.5 - 1.\n",
    "\n",
    "  for _ in range(5):\n",
    "    inference.update(feed_dict={y_ph: y_batch, x_ph: x_batch, phase: True, drop: 0.5}, variables=\"Disc\")\n",
    "#     diagn = sess.run(tf.concat([inference.dxt,inference.dxf,inference.dyt,inference.dyf],1),{y_ph: y_batch, x_ph: x_batch, phase: True})\n",
    "# #    print(diagn)\n",
    "#     asd2 = sess.run([inference.xp,inference.yp],{y_ph: y_batch, x_ph: x_batch, phase: True})\n",
    "# #    print(asd)\n",
    "#     if np.mean(diagn[0]) == 0.0:\n",
    "#         break\n",
    "#     if np.mean(diagn[2]) == 0.0:\n",
    "#         break\n",
    "#   else:\n",
    "#     info_dict = inference.update(feed_dict={y_ph: y_batch, x_ph: x_batch, phase: True}, variables=\"Gen\")\n",
    "#     inference.print_progress(info_dict)\n",
    "#     continue\n",
    "#   break\n",
    "  info_dict = inference.update(feed_dict={y_ph: y_batch, x_ph: x_batch, phase: True, drop: 0.5}, variables=\"Gen\")\n",
    "  inference.print_progress(info_dict)\n",
    "\n",
    "  \n",
    "  if i % inference.n_print == 0:\n",
    "    \n",
    "    idx = np.random.choice(M, 16, replace=False)\n",
    "    \n",
    "    fig = (x_batch[idx,] + 1.)/2.\n",
    "    fig = plot(fig)\n",
    "    plt.savefig(os.path.join(IMG_DIR+'/trainA/', '{}.jpg').format(\n",
    "        str(j).zfill(3)), bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    fig = (y_batch[idx,] + 1.)/2.\n",
    "    fig = plot(fig)\n",
    "    plt.savefig(os.path.join(IMG_DIR+'/trainB/', '{}.jpg').format(\n",
    "        str(j).zfill(3)), bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    D1sam = sess.run(xf, feed_dict={y_ph: y_batch, phase: True, drop: 0.0})\n",
    "    fig = (D1sam[idx,] + 1.)/2.\n",
    "    fig = plot(fig)\n",
    "    plt.savefig(os.path.join(IMG_DIR+'/trainBA/', '{}.jpg').format(\n",
    "       str(j).zfill(3)), bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    D2sam = sess.run(yf, feed_dict={x_ph: x_batch, phase: True, drop: 0.0})\n",
    "    fig = (D2sam[idx,] + 1.)/2.\n",
    "    fig = plot(fig)\n",
    "    plt.savefig(os.path.join(IMG_DIR+'/trainAB/', '{}.jpg').format(\n",
    "        str(j).zfill(3)), bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    D1recon = sess.run(xf, feed_dict={y_ph:D2sam, phase: True, drop: 0.0})\n",
    "    fig = (D1recon[idx,] + 1.)/2.\n",
    "    fig = plot(fig)\n",
    "    plt.savefig(os.path.join(IMG_DIR+'/trainABA/', '{}.jpg').format(\n",
    "        str(j).zfill(3)), bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    D2recon = sess.run(yf, feed_dict={x_ph: D1sam, phase: True, drop: 0.0})\n",
    "    fig = (D2recon[idx,] + 1.)/2.\n",
    "    fig = plot(fig)\n",
    "    plt.savefig(os.path.join(IMG_DIR+'/trainBAB/', '{}.jpg').format(\n",
    "        str(j).zfill(3)), bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "              \n",
    "    print('\\n Printing images for iteration: ' + str(j))\n",
    "    j += 1\n",
    "  i += 1\n",
    "\n",
    "inference.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var_list = tf.get_collection(\n",
    "          tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"Disc\")\n",
    "maxs = []\n",
    "mins = []\n",
    "for v in var_list:\n",
    "    maxs = maxs + [sess.run(tf.reduce_max(v))]\n",
    "    mins = mins + [sess.run(tf.reduce_min(v))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numVars = np.prod(tf.zeros([1]).shape)\n",
    "for var in var_list:\n",
    "    numVars += np.prod(var.shape)\n",
    "numVars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var_list = tf.get_collection(\n",
    "          tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"Gen\")\n",
    "maxs = []\n",
    "mins = []\n",
    "for v in var_list:\n",
    "    maxs = maxs + [sess.run(tf.reduce_max(v))]\n",
    "    mins = mins + [sess.run(tf.reduce_min(v))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D1sam = sess.run(yf, feed_dict={x_ph: x_batch, phase: True})\n",
    "\n",
    "fig = (D1sam[idx,] + 1.)/2\n",
    "fig = plot(fig)\n",
    "plt.show(fig)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
